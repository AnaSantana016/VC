{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "643c68d5",
   "metadata": {},
   "source": [
    "# Dector de género, raza, edad y emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1843aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.03it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  2.89it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.16it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.27it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.07it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  2.80it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "img = cv2.imread(\"images/img.png\")\n",
    "img = cv2.resize(img, (0, 0), None, 0.18, 0.18)\n",
    "ani, ali, c = img.shape\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    # Correccion de color\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Analizar la cara\n",
    "    info = DeepFace.analyze(rgb, actions=['age', 'gender', 'race', 'emotion'], enforce_detection=False)\n",
    "\n",
    "    # Mostrar información\n",
    "    if len(info) > 0:\n",
    "        # Tomamos solo la información del primer rostro detectado\n",
    "        primer_rostro = info[0]\n",
    "\n",
    "        # Edad, Emociones, Raza, Género\n",
    "        edad = primer_rostro['age']\n",
    "        emociones = primer_rostro['dominant_emotion']\n",
    "        race = primer_rostro['dominant_race']\n",
    "        gen = primer_rostro['dominant_gender']\n",
    "\n",
    "        frame[10:ani + 10, 10:ali + 10] = img\n",
    "\n",
    "        cv2.putText(frame, str(gen), (65, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        cv2.putText(frame, str(edad), (75, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        cv2.putText(frame, str(emociones), (75, 135), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        cv2.putText(frame, str(race), (75, 180), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "   \n",
    "    cv2.imshow('Vid', frame)\n",
    "\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "12028effb1af0cd2244438ff9b17d06bb1d7695ec7a554a144e43ec4b8b79006"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
